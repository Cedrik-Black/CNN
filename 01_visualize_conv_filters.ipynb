{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled30.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krakowiakpawel9/convnet-course/blob/master/01_visualize_conv_filters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq5q3MXbDQS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d662a3d7-1259-4ad4-afee-df1a8e7677e6"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image as pil_image\n",
        "from keras.preprocessing.image import save_img\n",
        "from keras import layers\n",
        "from keras.applications import vgg16\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def normalize(x):\n",
        "    \"\"\"utility function to normalize a tensor.\n",
        "\n",
        "    # Arguments\n",
        "        x: An input tensor.\n",
        "\n",
        "    # Returns\n",
        "        The normalized input tensor.\n",
        "    \"\"\"\n",
        "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n",
        "\n",
        "\n",
        "def deprocess_image(x):\n",
        "    \"\"\"utility function to convert a float array into a valid uint8 image.\n",
        "\n",
        "    # Arguments\n",
        "        x: A numpy-array representing the generated image.\n",
        "\n",
        "    # Returns\n",
        "        A processed numpy-array, which could be used in e.g. imshow.\n",
        "    \"\"\"\n",
        "    # normalize tensor: center on 0., ensure std is 0.25\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + K.epsilon())\n",
        "    x *= 0.25\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "\n",
        "def process_image(x, former):\n",
        "    \"\"\"utility function to convert a valid uint8 image back into a float array.\n",
        "       Reverses `deprocess_image`.\n",
        "\n",
        "    # Arguments\n",
        "        x: A numpy-array, which could be used in e.g. imshow.\n",
        "        former: The former numpy-array.\n",
        "                Need to determine the former mean and variance.\n",
        "\n",
        "    # Returns\n",
        "        A processed numpy-array representing the generated image.\n",
        "    \"\"\"\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        x = x.transpose((2, 0, 1))\n",
        "    return (x / 255 - 0.5) * 4 * former.std() + former.mean()\n",
        "\n",
        "\n",
        "def visualize_layer(model,\n",
        "                    layer_name,\n",
        "                    step=1.,\n",
        "                    epochs=15,\n",
        "                    upscaling_steps=9,\n",
        "                    upscaling_factor=1.2,\n",
        "                    output_dim=(412, 412),\n",
        "                    filter_range=(0, None)):\n",
        "    \"\"\"Visualizes the most relevant filters of one conv-layer in a certain model.\n",
        "\n",
        "    # Arguments\n",
        "        model: The model containing layer_name.\n",
        "        layer_name: The name of the layer to be visualized.\n",
        "                    Has to be a part of model.\n",
        "        step: step size for gradient ascent.\n",
        "        epochs: Number of iterations for gradient ascent.\n",
        "        upscaling_steps: Number of upscaling steps.\n",
        "                         Starting image is in this case (80, 80).\n",
        "        upscaling_factor: Factor to which to slowly upgrade\n",
        "                          the image towards output_dim.\n",
        "        output_dim: [img_width, img_height] The output image dimensions.\n",
        "        filter_range: Tupel[lower, upper]\n",
        "                      Determines the to be computed filter numbers.\n",
        "                      If the second value is `None`,\n",
        "                      the last filter will be inferred as the upper boundary.\n",
        "    \"\"\"\n",
        "\n",
        "    def _generate_filter_image(input_img,\n",
        "                               layer_output,\n",
        "                               filter_index):\n",
        "        \"\"\"Generates image for one particular filter.\n",
        "\n",
        "        # Arguments\n",
        "            input_img: The input-image Tensor.\n",
        "            layer_output: The output-image Tensor.\n",
        "            filter_index: The to be processed filter number.\n",
        "                          Assumed to be valid.\n",
        "\n",
        "        #Returns\n",
        "            Either None if no image could be generated.\n",
        "            or a tuple of the image (array) itself and the last loss.\n",
        "        \"\"\"\n",
        "        s_time = time.time()\n",
        "\n",
        "        # we build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            loss = K.mean(layer_output[:, filter_index, :, :])\n",
        "        else:\n",
        "            loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # we compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, input_img)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads = normalize(grads)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([input_img], [loss, grads])\n",
        "\n",
        "        # we start from a gray image with some random noise\n",
        "        intermediate_dim = tuple(\n",
        "            int(x / (upscaling_factor ** upscaling_steps)) for x in output_dim)\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            input_img_data = np.random.random(\n",
        "                (1, 3, intermediate_dim[0], intermediate_dim[1]))\n",
        "        else:\n",
        "            input_img_data = np.random.random(\n",
        "                (1, intermediate_dim[0], intermediate_dim[1], 3))\n",
        "        input_img_data = (input_img_data - 0.5) * 20 + 128\n",
        "\n",
        "        # Slowly upscaling towards the original size prevents\n",
        "        # a dominating high-frequency of the to visualized structure\n",
        "        # as it would occur if we directly compute the 412d-image.\n",
        "        # Behaves as a better starting point for each following dimension\n",
        "        # and therefore avoids poor local minima\n",
        "        for up in reversed(range(upscaling_steps)):\n",
        "            # we run gradient ascent for e.g. 20 steps\n",
        "            for _ in range(epochs):\n",
        "                loss_value, grads_value = iterate([input_img_data])\n",
        "                input_img_data += grads_value * step\n",
        "\n",
        "                # some filters get stuck to 0, we can skip them\n",
        "                if loss_value <= K.epsilon():\n",
        "                    return None\n",
        "\n",
        "            # Calulate upscaled dimension\n",
        "            intermediate_dim = tuple(\n",
        "                int(x / (upscaling_factor ** up)) for x in output_dim)\n",
        "            # Upscale\n",
        "            img = deprocess_image(input_img_data[0])\n",
        "            img = np.array(pil_image.fromarray(img).resize(intermediate_dim,\n",
        "                                                           pil_image.BICUBIC))\n",
        "            input_img_data = [process_image(img, input_img_data[0])]\n",
        "\n",
        "        # decode the resulting input image\n",
        "        img = deprocess_image(input_img_data[0])\n",
        "        e_time = time.time()\n",
        "        print('Costs of filter {:3}: {:5.0f} ( {:4.2f}s )'.format(filter_index,\n",
        "                                                                  loss_value,\n",
        "                                                                  e_time - s_time))\n",
        "        return img, loss_value\n",
        "\n",
        "    def _draw_filters(filters, n=None):\n",
        "        \"\"\"Draw the best filters in a nxn grid.\n",
        "\n",
        "        # Arguments\n",
        "            filters: A List of generated images and their corresponding losses\n",
        "                     for each processed filter.\n",
        "            n: dimension of the grid.\n",
        "               If none, the largest possible square will be used\n",
        "        \"\"\"\n",
        "        if n is None:\n",
        "            n = int(np.floor(np.sqrt(len(filters))))\n",
        "\n",
        "        # the filters that have the highest loss are assumed to be better-looking.\n",
        "        # we will only keep the top n*n filters.\n",
        "        filters.sort(key=lambda x: x[1], reverse=True)\n",
        "        filters = filters[:n * n]\n",
        "\n",
        "        # build a black picture with enough space for\n",
        "        # e.g. our 8 x 8 filters of size 412 x 412, with a 5px margin in between\n",
        "        MARGIN = 5\n",
        "        width = n * output_dim[0] + (n - 1) * MARGIN\n",
        "        height = n * output_dim[1] + (n - 1) * MARGIN\n",
        "        stitched_filters = np.zeros((width, height, 3), dtype='uint8')\n",
        "\n",
        "        # fill the picture with our saved filters\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                img, _ = filters[i * n + j]\n",
        "                width_margin = (output_dim[0] + MARGIN) * i\n",
        "                height_margin = (output_dim[1] + MARGIN) * j\n",
        "                stitched_filters[\n",
        "                    width_margin: width_margin + output_dim[0],\n",
        "                    height_margin: height_margin + output_dim[1], :] = img\n",
        "\n",
        "        # save the result to disk\n",
        "        save_img('vgg_{0:}_{1:}x{1:}.png'.format(layer_name, n), stitched_filters)\n",
        "\n",
        "    # this is the placeholder for the input images\n",
        "    assert len(model.inputs) == 1\n",
        "    input_img = model.inputs[0]\n",
        "\n",
        "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
        "\n",
        "    output_layer = layer_dict[layer_name]\n",
        "    assert isinstance(output_layer, layers.Conv2D)\n",
        "\n",
        "    # Compute to be processed filter range\n",
        "    filter_lower = filter_range[0]\n",
        "    filter_upper = (filter_range[1]\n",
        "                    if filter_range[1] is not None\n",
        "                    else len(output_layer.get_weights()[1]))\n",
        "    assert(filter_lower >= 0\n",
        "           and filter_upper <= len(output_layer.get_weights()[1])\n",
        "           and filter_upper > filter_lower)\n",
        "    print('Compute filters {:} to {:}'.format(filter_lower, filter_upper))\n",
        "\n",
        "    # iterate through each filter and generate its corresponding image\n",
        "    processed_filters = []\n",
        "    for f in range(filter_lower, filter_upper):\n",
        "        img_loss = _generate_filter_image(input_img, output_layer.output, f)\n",
        "\n",
        "        if img_loss is not None:\n",
        "            processed_filters.append(img_loss)\n",
        "\n",
        "    print('{} filter processed.'.format(len(processed_filters)))\n",
        "    # Finally draw and store the best filters to disk\n",
        "    _draw_filters(processed_filters)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # the name of the layer we want to visualize\n",
        "    # (see model definition at keras/applications/vgg16.py)\n",
        "    LAYER_NAME = 'block5_conv1'\n",
        "\n",
        "    # build the VGG16 network with ImageNet weights\n",
        "    vgg = vgg16.VGG16(weights='imagenet', include_top=False)\n",
        "    print('Model loaded.')\n",
        "    vgg.summary()\n",
        "\n",
        "    # example function call\n",
        "    visualize_layer(vgg, LAYER_NAME)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0709 19:00:33.749072 140642010498944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0709 19:00:33.782401 140642010498944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0709 19:00:33.789200 140642010498944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0709 19:00:33.828401 140642010498944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0709 19:00:34.858874 140642010498944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0709 19:00:34.859922 140642010498944 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model loaded.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Compute filters 0 to 512\n",
            "Costs of filter   0:   404 ( 14.55s )\n",
            "Costs of filter   2:   429 ( 2.28s )\n",
            "Costs of filter   3:   523 ( 2.26s )\n",
            "Costs of filter   4:   589 ( 2.27s )\n",
            "Costs of filter   5:   507 ( 2.30s )\n",
            "Costs of filter   7:   948 ( 2.30s )\n",
            "Costs of filter   8:   873 ( 2.32s )\n",
            "Costs of filter   9:   474 ( 2.34s )\n",
            "Costs of filter  11:   769 ( 2.38s )\n",
            "Costs of filter  13:   353 ( 2.36s )\n",
            "Costs of filter  14:   693 ( 2.38s )\n",
            "Costs of filter  15:   501 ( 2.40s )\n",
            "Costs of filter  17:   839 ( 2.41s )\n",
            "Costs of filter  20:   528 ( 2.44s )\n",
            "Costs of filter  24:   454 ( 2.44s )\n",
            "Costs of filter  25:   568 ( 2.47s )\n",
            "Costs of filter  27:   934 ( 2.43s )\n",
            "Costs of filter  28:   521 ( 2.44s )\n",
            "Costs of filter  29:   551 ( 2.47s )\n",
            "Costs of filter  30:   594 ( 2.44s )\n",
            "Costs of filter  31:   396 ( 2.43s )\n",
            "Costs of filter  32:   376 ( 2.44s )\n",
            "Costs of filter  36:   828 ( 2.45s )\n",
            "Costs of filter  37:   791 ( 2.45s )\n",
            "Costs of filter  39:   564 ( 2.46s )\n",
            "Costs of filter  42:   844 ( 2.45s )\n",
            "Costs of filter  43:   413 ( 2.46s )\n",
            "Costs of filter  44:   618 ( 2.46s )\n",
            "Costs of filter  46:   970 ( 2.48s )\n",
            "Costs of filter  47:   686 ( 2.48s )\n",
            "Costs of filter  48:   669 ( 2.48s )\n",
            "Costs of filter  49:   814 ( 2.50s )\n",
            "Costs of filter  51:   487 ( 2.50s )\n",
            "Costs of filter  53:   694 ( 2.49s )\n",
            "Costs of filter  55:   412 ( 2.52s )\n",
            "Costs of filter  58:   330 ( 2.54s )\n",
            "Costs of filter  59:   870 ( 2.54s )\n",
            "Costs of filter  60:   740 ( 2.56s )\n",
            "Costs of filter  61:   920 ( 2.58s )\n",
            "Costs of filter  62:   624 ( 2.72s )\n",
            "Costs of filter  63:  1098 ( 2.58s )\n",
            "Costs of filter  64:  1222 ( 2.58s )\n",
            "Costs of filter  65:   208 ( 2.58s )\n",
            "Costs of filter  70:   579 ( 2.69s )\n",
            "Costs of filter  73:   702 ( 2.66s )\n",
            "Costs of filter  74:   513 ( 2.64s )\n",
            "Costs of filter  75:   302 ( 2.66s )\n",
            "Costs of filter  76:   822 ( 2.66s )\n",
            "Costs of filter  79:   797 ( 2.67s )\n",
            "Costs of filter  80:   443 ( 2.72s )\n",
            "Costs of filter  81:   486 ( 2.68s )\n",
            "Costs of filter  82:   597 ( 2.70s )\n",
            "Costs of filter  84:   535 ( 2.77s )\n",
            "Costs of filter  86:  1007 ( 2.73s )\n",
            "Costs of filter  87:   786 ( 2.76s )\n",
            "Costs of filter  88:   908 ( 2.80s )\n",
            "Costs of filter  89:   691 ( 2.76s )\n",
            "Costs of filter  91:   675 ( 2.97s )\n",
            "Costs of filter  92:   432 ( 2.74s )\n",
            "Costs of filter  93:   616 ( 2.76s )\n",
            "Costs of filter  95:   321 ( 2.78s )\n",
            "Costs of filter  97:   446 ( 2.76s )\n",
            "Costs of filter  99:   458 ( 2.78s )\n",
            "Costs of filter 101:   351 ( 2.80s )\n",
            "Costs of filter 103:   972 ( 2.78s )\n",
            "Costs of filter 110:   651 ( 2.88s )\n",
            "Costs of filter 112:   311 ( 2.84s )\n",
            "Costs of filter 113:   626 ( 2.88s )\n",
            "Costs of filter 114:   742 ( 2.87s )\n",
            "Costs of filter 119:   838 ( 2.96s )\n",
            "Costs of filter 121:   438 ( 2.90s )\n",
            "Costs of filter 123:   460 ( 2.88s )\n",
            "Costs of filter 124:   341 ( 2.92s )\n",
            "Costs of filter 126:   961 ( 2.96s )\n",
            "Costs of filter 127:   422 ( 3.17s )\n",
            "Costs of filter 128:   854 ( 2.96s )\n",
            "Costs of filter 131:   568 ( 3.12s )\n",
            "Costs of filter 132:   375 ( 3.01s )\n",
            "Costs of filter 133:   523 ( 3.06s )\n",
            "Costs of filter 135:   419 ( 3.02s )\n",
            "Costs of filter 136:   710 ( 3.00s )\n",
            "Costs of filter 137:   400 ( 3.04s )\n",
            "Costs of filter 138:  1367 ( 3.01s )\n",
            "Costs of filter 139:   393 ( 3.04s )\n",
            "Costs of filter 140:   506 ( 3.02s )\n",
            "Costs of filter 141:   578 ( 3.03s )\n",
            "Costs of filter 143:   840 ( 3.04s )\n",
            "Costs of filter 145:   493 ( 3.11s )\n",
            "Costs of filter 146:  1201 ( 3.05s )\n",
            "Costs of filter 149:   511 ( 3.11s )\n",
            "Costs of filter 151:   559 ( 3.11s )\n",
            "Costs of filter 152:   592 ( 3.07s )\n",
            "Costs of filter 153:   503 ( 3.10s )\n",
            "Costs of filter 154:   655 ( 3.09s )\n",
            "Costs of filter 155:   459 ( 3.09s )\n",
            "Costs of filter 157:   880 ( 3.18s )\n",
            "Costs of filter 158:   714 ( 3.14s )\n",
            "Costs of filter 161:   455 ( 3.20s )\n",
            "Costs of filter 162:   621 ( 3.16s )\n",
            "Costs of filter 165:   506 ( 3.23s )\n",
            "Costs of filter 166:   717 ( 3.17s )\n",
            "Costs of filter 167:   681 ( 3.18s )\n",
            "Costs of filter 170:   756 ( 3.25s )\n",
            "Costs of filter 171:   655 ( 3.39s )\n",
            "Costs of filter 174:   631 ( 3.26s )\n",
            "Costs of filter 175:   469 ( 3.29s )\n",
            "Costs of filter 177:   766 ( 3.30s )\n",
            "Costs of filter 180:   418 ( 3.32s )\n",
            "Costs of filter 181:   655 ( 3.37s )\n",
            "Costs of filter 182:  1147 ( 3.29s )\n",
            "Costs of filter 185:   633 ( 3.34s )\n",
            "Costs of filter 186:   505 ( 3.37s )\n",
            "Costs of filter 187:   971 ( 3.31s )\n",
            "Costs of filter 188:   533 ( 3.38s )\n",
            "Costs of filter 189:   510 ( 3.34s )\n",
            "Costs of filter 190:   475 ( 3.36s )\n",
            "Costs of filter 201:   462 ( 3.42s )\n",
            "Costs of filter 202:   536 ( 3.37s )\n",
            "Costs of filter 203:   529 ( 3.44s )\n",
            "Costs of filter 204:   434 ( 3.40s )\n",
            "Costs of filter 206:   519 ( 3.49s )\n",
            "Costs of filter 207:   362 ( 3.50s )\n",
            "Costs of filter 208:   975 ( 3.47s )\n",
            "Costs of filter 209:   745 ( 3.58s )\n",
            "Costs of filter 211:   377 ( 3.53s )\n",
            "Costs of filter 212:   362 ( 3.52s )\n",
            "Costs of filter 213:   806 ( 3.49s )\n",
            "Costs of filter 214:   539 ( 3.50s )\n",
            "Costs of filter 218:   470 ( 3.56s )\n",
            "Costs of filter 219:   834 ( 3.50s )\n",
            "Costs of filter 220:   821 ( 3.52s )\n",
            "Costs of filter 221:   573 ( 3.59s )\n",
            "Costs of filter 223:   372 ( 3.60s )\n",
            "Costs of filter 224:   531 ( 3.63s )\n",
            "Costs of filter 225:   178 ( 3.58s )\n",
            "Costs of filter 227:   449 ( 3.62s )\n",
            "Costs of filter 229:   979 ( 3.66s )\n",
            "Costs of filter 232:   929 ( 3.67s )\n",
            "Costs of filter 233:   383 ( 3.59s )\n",
            "Costs of filter 234:   682 ( 3.62s )\n",
            "Costs of filter 235:   776 ( 3.63s )\n",
            "Costs of filter 236:   564 ( 3.65s )\n",
            "Costs of filter 237:   578 ( 3.65s )\n",
            "Costs of filter 238:   603 ( 3.64s )\n",
            "Costs of filter 240:   511 ( 3.71s )\n",
            "Costs of filter 241:   718 ( 3.80s )\n",
            "Costs of filter 243:   797 ( 3.70s )\n",
            "Costs of filter 245:   996 ( 3.71s )\n",
            "Costs of filter 246:   379 ( 3.69s )\n",
            "Costs of filter 247:   508 ( 3.76s )\n",
            "Costs of filter 249:   577 ( 3.80s )\n",
            "Costs of filter 250:  1039 ( 3.72s )\n",
            "Costs of filter 251:   467 ( 3.74s )\n",
            "Costs of filter 255:   636 ( 3.81s )\n",
            "Costs of filter 257:   569 ( 3.79s )\n",
            "Costs of filter 258:   610 ( 3.80s )\n",
            "Costs of filter 260:   432 ( 3.86s )\n",
            "Costs of filter 262:   455 ( 4.06s )\n",
            "Costs of filter 263:   573 ( 3.86s )\n",
            "Costs of filter 265:   850 ( 3.92s )\n",
            "Costs of filter 267:   376 ( 3.92s )\n",
            "Costs of filter 268:   507 ( 3.92s )\n",
            "Costs of filter 269:   621 ( 3.90s )\n",
            "Costs of filter 270:  1388 ( 3.90s )\n",
            "Costs of filter 271:   608 ( 3.95s )\n",
            "Costs of filter 275:   539 ( 3.94s )\n",
            "Costs of filter 278:   637 ( 3.96s )\n",
            "Costs of filter 279:   650 ( 3.94s )\n",
            "Costs of filter 280:   255 ( 3.96s )\n",
            "Costs of filter 281:   593 ( 3.97s )\n",
            "Costs of filter 282:   478 ( 4.00s )\n",
            "Costs of filter 285:   629 ( 4.00s )\n",
            "Costs of filter 286:   970 ( 4.11s )\n",
            "Costs of filter 287:   479 ( 4.08s )\n",
            "Costs of filter 289:   478 ( 4.01s )\n",
            "Costs of filter 293:   468 ( 4.06s )\n",
            "Costs of filter 294:   697 ( 4.09s )\n",
            "Costs of filter 295:   837 ( 4.12s )\n",
            "Costs of filter 296:   438 ( 4.13s )\n",
            "Costs of filter 297:   658 ( 4.16s )\n",
            "Costs of filter 299:   476 ( 4.18s )\n",
            "Costs of filter 300:  1055 ( 4.17s )\n",
            "Costs of filter 302:   934 ( 4.13s )\n",
            "Costs of filter 303:   550 ( 4.17s )\n",
            "Costs of filter 305:   448 ( 4.15s )\n",
            "Costs of filter 306:   713 ( 4.21s )\n",
            "Costs of filter 308:   706 ( 4.16s )\n",
            "Costs of filter 309:  1309 ( 4.21s )\n",
            "Costs of filter 311:   467 ( 4.17s )\n",
            "Costs of filter 313:   843 ( 4.30s )\n",
            "Costs of filter 320:   617 ( 4.20s )\n",
            "Costs of filter 322:   737 ( 4.24s )\n",
            "Costs of filter 323:   566 ( 4.29s )\n",
            "Costs of filter 328:   736 ( 4.36s )\n",
            "Costs of filter 331:   568 ( 4.41s )\n",
            "Costs of filter 333:   416 ( 4.41s )\n",
            "Costs of filter 334:   778 ( 4.48s )\n",
            "Costs of filter 336:   512 ( 4.41s )\n",
            "Costs of filter 338:   768 ( 4.45s )\n",
            "Costs of filter 339:   621 ( 4.43s )\n",
            "Costs of filter 341:   408 ( 4.42s )\n",
            "Costs of filter 342:   567 ( 4.43s )\n",
            "Costs of filter 343:   318 ( 4.43s )\n",
            "Costs of filter 345:   475 ( 4.47s )\n",
            "Costs of filter 346:   940 ( 4.59s )\n",
            "Costs of filter 348:   743 ( 4.62s )\n",
            "Costs of filter 349:   488 ( 4.54s )\n",
            "Costs of filter 352:   606 ( 4.53s )\n",
            "Costs of filter 353:   667 ( 4.59s )\n",
            "Costs of filter 356:   734 ( 4.54s )\n",
            "Costs of filter 357:   465 ( 4.60s )\n",
            "Costs of filter 359:   589 ( 4.55s )\n",
            "Costs of filter 360:   383 ( 4.67s )\n",
            "Costs of filter 361:   533 ( 4.59s )\n",
            "Costs of filter 362:   611 ( 4.65s )\n",
            "Costs of filter 365:   780 ( 4.63s )\n",
            "Costs of filter 367:   725 ( 4.56s )\n",
            "Costs of filter 368:   927 ( 4.58s )\n",
            "Costs of filter 371:  1235 ( 4.69s )\n",
            "Costs of filter 374:   540 ( 4.61s )\n",
            "Costs of filter 375:   570 ( 4.65s )\n",
            "Costs of filter 376:   985 ( 4.73s )\n",
            "Costs of filter 377:   698 ( 4.65s )\n",
            "Costs of filter 378:   579 ( 4.76s )\n",
            "Costs of filter 380:   504 ( 4.71s )\n",
            "Costs of filter 381:   516 ( 4.69s )\n",
            "Costs of filter 383:   985 ( 4.68s )\n",
            "Costs of filter 387:   686 ( 4.69s )\n",
            "Costs of filter 389:   516 ( 4.69s )\n",
            "Costs of filter 394:   596 ( 4.72s )\n",
            "Costs of filter 399:   782 ( 4.80s )\n",
            "Costs of filter 401:   493 ( 4.82s )\n",
            "Costs of filter 402:   393 ( 4.82s )\n",
            "Costs of filter 405:   683 ( 4.89s )\n",
            "Costs of filter 410:   281 ( 4.81s )\n",
            "Costs of filter 412:   815 ( 4.87s )\n",
            "Costs of filter 414:   438 ( 5.03s )\n",
            "Costs of filter 415:   953 ( 5.07s )\n",
            "Costs of filter 416:   398 ( 4.94s )\n",
            "Costs of filter 417:   668 ( 4.97s )\n",
            "Costs of filter 418:   646 ( 5.04s )\n",
            "Costs of filter 421:   514 ( 4.98s )\n",
            "Costs of filter 422:   465 ( 4.91s )\n",
            "Costs of filter 423:   756 ( 4.92s )\n",
            "Costs of filter 424:   619 ( 4.99s )\n",
            "Costs of filter 427:   583 ( 4.91s )\n",
            "Costs of filter 428:   707 ( 5.15s )\n",
            "Costs of filter 430:   461 ( 4.96s )\n",
            "Costs of filter 433:   627 ( 5.11s )\n",
            "Costs of filter 435:   543 ( 5.05s )\n",
            "Costs of filter 436:   832 ( 5.12s )\n",
            "Costs of filter 437:   728 ( 5.07s )\n",
            "Costs of filter 438:   693 ( 5.14s )\n",
            "Costs of filter 439:   813 ( 5.33s )\n",
            "Costs of filter 442:   703 ( 5.09s )\n",
            "Costs of filter 444:   663 ( 5.20s )\n",
            "Costs of filter 445:   430 ( 5.09s )\n",
            "Costs of filter 449:   529 ( 5.12s )\n",
            "Costs of filter 452:   691 ( 5.30s )\n",
            "Costs of filter 453:   622 ( 5.18s )\n",
            "Costs of filter 457:   589 ( 5.18s )\n",
            "Costs of filter 458:   707 ( 5.27s )\n",
            "Costs of filter 460:   727 ( 5.22s )\n",
            "Costs of filter 461:   436 ( 5.23s )\n",
            "Costs of filter 462:   475 ( 5.25s )\n",
            "Costs of filter 463:   214 ( 5.21s )\n",
            "Costs of filter 464:   434 ( 5.24s )\n",
            "Costs of filter 465:   474 ( 5.24s )\n",
            "Costs of filter 466:   480 ( 5.24s )\n",
            "Costs of filter 467:   455 ( 5.24s )\n",
            "Costs of filter 473:   719 ( 5.28s )\n",
            "Costs of filter 474:   462 ( 5.23s )\n",
            "Costs of filter 475:   431 ( 5.34s )\n",
            "Costs of filter 476:   534 ( 5.30s )\n",
            "Costs of filter 478:   446 ( 5.40s )\n",
            "Costs of filter 481:   616 ( 5.30s )\n",
            "Costs of filter 482:   316 ( 5.34s )\n",
            "Costs of filter 483:   503 ( 5.35s )\n",
            "Costs of filter 484:   331 ( 5.37s )\n",
            "Costs of filter 485:   999 ( 5.43s )\n",
            "Costs of filter 487:   609 ( 5.49s )\n",
            "Costs of filter 489:   623 ( 5.47s )\n",
            "Costs of filter 490:   639 ( 5.45s )\n",
            "Costs of filter 493:   602 ( 5.44s )\n",
            "Costs of filter 494:   774 ( 5.84s )\n",
            "Costs of filter 495:   637 ( 5.42s )\n",
            "Costs of filter 496:   467 ( 5.45s )\n",
            "Costs of filter 499:   651 ( 5.54s )\n",
            "Costs of filter 500:   761 ( 5.55s )\n",
            "Costs of filter 501:   624 ( 5.49s )\n",
            "Costs of filter 502:   521 ( 5.59s )\n",
            "Costs of filter 503:   471 ( 5.47s )\n",
            "Costs of filter 505:   821 ( 5.48s )\n",
            "Costs of filter 506:   438 ( 5.53s )\n",
            "Costs of filter 509:   462 ( 5.57s )\n",
            "Costs of filter 510:   565 ( 5.60s )\n",
            "Costs of filter 511:   909 ( 5.61s )\n",
            "297 filter processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2a_e5H7Tgyr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1b2ed365-7070-4fc7-b5f6-82697da9aa05"
      },
      "source": [
        "__name__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'__main__'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZbN6TbnTwFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}